{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERLI - AI4Industry - 2025\n",
    "\n",
    "---\n",
    "Notebook du Groupe rouge foncé (on aurait préféré le bleu)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import threading\n",
    "from scipy.ndimage import label\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"dataset/\"\n",
    "DATASET_LIGHT_FOLDER = \"dataset_light/dataset/\"\n",
    "USE_LIGHT_DATASET = True\n",
    "\n",
    "USE_MEMORY_SAVING = True # If False, can crash the kernel\n",
    "USE_OPENCV = True\n",
    "\n",
    "IMAGE_SIZE = (848, 480)\n",
    "MASK_FILE = \"mask1.png\"\n",
    "\n",
    "SEED = int(time.time())\n",
    "BATCH_SIZE = 8\n",
    "TEST_SPLIT = 0.1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "LIMIT_LAT_MIN = 47.3947574\n",
    "LIMIT_LON_MIN = -1.1866685\n",
    "LIMIT_LAT_MAX = 47.3968351\n",
    "LIMIT_LON_MAX = -1.1841471"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lock = threading.Lock()\n",
    "\n",
    "def read_subfolder(subfolder_path, image_size, image_list, label_list):\n",
    "    print(f\"Reading subfolder: {subfolder_path}\")\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        if file.endswith('.png'):\n",
    "            image_path = os.path.join(subfolder_path, file)\n",
    "            file_name = file.split(\".\")[0]\n",
    "            json_path = os.path.join(subfolder_path, file_name + \".json\")\n",
    "\n",
    "            if USE_LIGHT_DATASET:\n",
    "                index = int(int(file_name.split(\"_\")[1])/10)\n",
    "            else:\n",
    "                index = int(file_name.split(\"_\")[1])\n",
    "\n",
    "            if os.path.exists(json_path) and os.path.exists(image_path):\n",
    "                with data_lock:\n",
    "                    image_list[index-1] = str(image_path)\n",
    "                    with open(json_path) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                        label_list[index-1] = data\n",
    "            else:\n",
    "                print(f\"json file does not exist for: {file}\")\n",
    "    print(f\"Finished reading subfolder: {subfolder_path}\")\n",
    "\n",
    "if os.path.exists(DATASET_FOLDER) and os.path.exists(DATASET_LIGHT_FOLDER):\n",
    "    print(\"Dataset folder exists\")\n",
    "    \n",
    "    folder = DATASET_FOLDER if not USE_LIGHT_DATASET else DATASET_LIGHT_FOLDER\n",
    "    dataset_len = 0\n",
    "    for subfolders in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolders)\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith('.png'):\n",
    "                dataset_len += 1\n",
    "                \n",
    "    image_list = np.zeros((dataset_len), dtype=object)\n",
    "    label_list = np.zeros((dataset_len), dtype=object)\n",
    "    \n",
    "    threads = []\n",
    "\n",
    "    # Lancer un thread pour chaque sous-dossier\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            thread = threading.Thread(target=read_subfolder, args=(subfolder_path, IMAGE_SIZE, image_list, label_list))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "    # Attendre que tous les threads soient terminés\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "else:\n",
    "    raise Exception(\"Dataset folder does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Dataset length: {len(image_list)}\")\n",
    "print (f\"Label length: {len(label_list)}\")\n",
    "print (f\"Image list: {image_list[:5]}\")\n",
    "print (f\"Label list: {label_list[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_OPENCV:\n",
    "    mask = cv2.imread(MASK_FILE, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "else:\n",
    "    mask = tf.io.read_file(MASK_FILE)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, IMAGE_SIZE)\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0\n",
    "\n",
    "def load_image(image_path):\n",
    "    if USE_OPENCV:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "        image = image / 255.0\n",
    "        image = cv2.bitwise_and(image, image, mask=mask)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    else:\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.resize(image, IMAGE_SIZE)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = image * mask\n",
    "    \n",
    "    return image\n",
    "\n",
    "def compute_position(position):\n",
    "    lat = position[\"lat\"]\n",
    "    lon = position[\"lon\"]\n",
    "    x = (lon - LIMIT_LON_MIN) / (LIMIT_LON_MAX - LIMIT_LON_MIN)\n",
    "    y = (lat - LIMIT_LAT_MIN) / (LIMIT_LAT_MAX - LIMIT_LAT_MIN)\n",
    "    return (x, y)\n",
    "\n",
    "def image_generator(frames, positions):\n",
    "    for image_path, position in zip(frames, positions):\n",
    "        if os.path.exists(image_path):\n",
    "            yield load_image(image_path), compute_position(position)\n",
    "        else:\n",
    "            print(f\"Image manquante : {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MEMORY_SAVING:\n",
    "    # Générateur d'images\n",
    "    generator = lambda: image_generator(image_list, label_list)\n",
    "\n",
    "    # Création du dataset à partir du générateur\n",
    "    dataset = Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(2,), dtype=tf.float32)  # Ajustez selon le format de `positions`\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mélange, division et batch du dataset\n",
    "    dataset = dataset.shuffle(buffer_size=1000, seed=SEED)\n",
    "\n",
    "    dataset_length = len(image_list)\n",
    "    dataset = dataset.apply(tf.data.experimental.assert_cardinality(dataset_length))\n",
    "\n",
    "    validation_size = int(dataset_length * VALIDATION_SPLIT)\n",
    "    test_size = int(dataset_length * TEST_SPLIT)\n",
    "\n",
    "    dataset_validation = dataset.take(validation_size).batch(BATCH_SIZE)\n",
    "    dataset_test = dataset.skip(validation_size).take(test_size).batch(BATCH_SIZE)\n",
    "    dataset_train = dataset.skip(validation_size + test_size).batch(BATCH_SIZE)\n",
    "    \n",
    "    dataset_train = dataset_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_validation = dataset_validation.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_test = dataset_test.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "else:\n",
    "    dataset_length = len(image_list)\n",
    "\n",
    "    images = np.zeros((dataset_length, IMAGE_SIZE[0], IMAGE_SIZE[1], 1), dtype=np.float32)\n",
    "    positions = np.zeros((dataset_length, 2), dtype=np.float32)\n",
    "    \n",
    "    for i in tqdm(range(dataset_length)):\n",
    "        image = load_image(image_list[i])\n",
    "        images[i] = image\n",
    "        positions[i] = compute_position(label_list[i])\n",
    "\n",
    "    dataset_images = Dataset.from_tensor_slices(images)\n",
    "    dataset_positions = Dataset.from_tensor_slices(positions)\n",
    "\n",
    "    dataset = Dataset.zip((dataset_images, dataset_positions)).shuffle(SEED)\n",
    "\n",
    "    dataset_validation = dataset.take(int(dataset_length * VALIDATION_SPLIT))\n",
    "    dataset_test = dataset.skip(len(dataset_validation)).take(int(dataset_length * TEST_SPLIT))\n",
    "    dataset_train = dataset.skip(len(dataset_validation) + len(dataset_test)).take(dataset_length - len(dataset_validation) - len(dataset_test))\n",
    "\n",
    "    dataset_validation = dataset_validation.batch(BATCH_SIZE)\n",
    "    dataset_test = dataset_test.batch(BATCH_SIZE)\n",
    "    dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Datasets shapes:\")\n",
    "print(dataset_train.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), output_shape=2, model_name=\"cnn_model\"):\n",
    "    inputs = L.Input(shape=input_shape, name=f'{model_name}_input')\n",
    "    x = L.Conv2D(3, kernel_size=7, activation='relu', padding='same', name=f'{model_name}_conv2D_3_7')(inputs)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_3_7')(x)\n",
    "    x = L.Conv2D(16, kernel_size=5, activation='relu', padding='same', name=f'{model_name}_conv2D_16_5')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_16_5')(x)\n",
    "    x = L.Conv2D(48, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_48_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_48_3')(x)\n",
    "    x = L.Conv2D(24, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_24_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_24_3')(x)\n",
    "    x = L.Conv2D(12, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_12_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_12_3')(x)\n",
    "    x = L.Dropout(0.5, name=f'{model_name}_dropout')(x)\n",
    "    x = L.Flatten(name=f'{model_name}_flatten')(x)\n",
    "    x = L.Dense(256, activation='relu', name=f'{model_name}_dense_256')(x)\n",
    "    x = L.Dense(128, activation='relu', name=f'{model_name}_dense_128')(x)\n",
    "    outputs = L.Dense(output_shape, activation='softmax', name=f'{model_name}_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset_train, validation_data=dataset_validation, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
