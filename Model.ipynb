{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERLI - AI4Industry - 2025\n",
    "\n",
    "---\n",
    "Notebook du Groupe rouge foncé (on aurait préféré le bleu)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import threading\n",
    "from scipy.ndimage import label\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "from codecarbon import EmissionsTracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_FOLDER = \"mask/\"\n",
    "\n",
    "DATASET_FOLDER = \"dataset/\"\n",
    "DATASET_LIGHT_FOLDER = \"dataset_light/dataset/\"\n",
    "USE_LIGHT_DATASET = True\n",
    "\n",
    "USE_MEMORY_SAVING = True # If False, can crash the kernel\n",
    "USE_OPENCV = False\n",
    "\n",
    "IMAGE_SIZE = (848, 480)\n",
    "MASK_FILE = \"mask1.png\"\n",
    "\n",
    "SEED = int(time.time())\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TEST_SPLIT = 0.1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "LIMIT_LAT_MIN = 47.3947574\n",
    "LIMIT_LON_MIN = -1.1866685\n",
    "LIMIT_LAT_MAX = 47.3968351\n",
    "LIMIT_LON_MAX = -1.1841471"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertArrayToImage(array, index) :\n",
    "    dataset_folder = DATASET_FOLDER if not USE_LIGHT_DATASET else DATASET_LIGHT_FOLDER\n",
    "    file_id = (index + 1) * 10 if USE_LIGHT_DATASET else (index + 1)\n",
    "    file_name = \"part\" + \"{:03d}\".format(file_id // 1000) + \"/mask_\" + str(file_id) + \".png\"\n",
    "    \n",
    "    array = (array * 255).astype(np.uint8)  # Convert boolean array to uint8\n",
    "    cv2.imwrite(os.path.join(dataset_folder, file_name), cv2.cvtColor(array, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "for file_id, file in enumerate(os.listdir(MASK_FOLDER)) :\n",
    "    array = np.load(os.path.join(MASK_FOLDER, file))\n",
    "    for c, arr in enumerate(array) :\n",
    "        convertArrayToImage(arr, file_id * 50 + c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lock = threading.Lock()\n",
    "\n",
    "def read_subfolder(subfolder_path, image_size, image_list, label_list):\n",
    "    print(f\"Reading subfolder: {subfolder_path}\")\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        if file.endswith('.png') and file.startswith(\"frame_\"):\n",
    "            id = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "            image_path = os.path.join(subfolder_path, \"mask_\" + str(id) + \".png\")\n",
    "            if (not os.path.exists(image_path)):\n",
    "                print(f\"Image does not exist for: {file}\")\n",
    "            file_name = file.split(\".\")[0]\n",
    "            json_path = os.path.join(subfolder_path, file_name + \".json\")\n",
    "\n",
    "            if USE_LIGHT_DATASET:\n",
    "                index = int(int(file_name.split(\"_\")[1])/10)\n",
    "            else:\n",
    "                index = int(file_name.split(\"_\")[1])\n",
    "\n",
    "            if os.path.exists(json_path) and os.path.exists(image_path):\n",
    "                with data_lock:\n",
    "                    image_list[index-1] = str(image_path)\n",
    "                    with open(json_path) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                        label_list[index-1] = data\n",
    "            else:\n",
    "                print(f\"json file does not exist for: {file}\")\n",
    "    print(f\"Finished reading subfolder: {subfolder_path}\")\n",
    "\n",
    "if os.path.exists(DATASET_FOLDER) and os.path.exists(DATASET_LIGHT_FOLDER):\n",
    "    print(\"Dataset folder exists\")\n",
    "    \n",
    "    folder = DATASET_FOLDER if not USE_LIGHT_DATASET else DATASET_LIGHT_FOLDER\n",
    "    dataset_len = 0\n",
    "    for subfolders in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolders)\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith('.png') and file.startswith(\"frame_\"):\n",
    "                dataset_len += 1\n",
    "                \n",
    "    image_list = np.zeros((dataset_len), dtype=object)\n",
    "    label_list = np.zeros((dataset_len), dtype=object)\n",
    "    \n",
    "    threads = []\n",
    "\n",
    "    # Lancer un thread pour chaque sous-dossier\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            thread = threading.Thread(target=read_subfolder, args=(subfolder_path, IMAGE_SIZE, image_list, label_list))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "    # Attendre que tous les threads soient terminés\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "else:\n",
    "    raise Exception(\"Dataset folder does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Dataset length: {len(image_list)}\")\n",
    "print (f\"Label length: {len(label_list)}\")\n",
    "print (f\"Image list: {image_list[:5]}\")\n",
    "print (f\"Label list: {label_list[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if USE_OPENCV:\n",
    "    mask = cv2.imread(MASK_FILE, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "else:\n",
    "    mask = tf.io.read_file(MASK_FILE)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, IMAGE_SIZE)\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0\n",
    "\n",
    "def load_image(image_path):\n",
    "    if USE_OPENCV:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "        image = image / 255.0\n",
    "        image = cv2.bitwise_and(image, image, mask=mask)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    else:\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.resize(image, IMAGE_SIZE)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = image * mask\n",
    "    \n",
    "    return image\n",
    "\n",
    "def compute_position(position):\n",
    "    lat = position[\"lat\"]\n",
    "    lon = position[\"lon\"]\n",
    "    x = (lon - LIMIT_LON_MIN) / (LIMIT_LON_MAX - LIMIT_LON_MIN)\n",
    "    y = (lat - LIMIT_LAT_MIN) / (LIMIT_LAT_MAX - LIMIT_LAT_MIN)\n",
    "    return (x, y)\n",
    "\n",
    "def image_generator(frames, positions):\n",
    "    for image_path, position in zip(frames, positions):\n",
    "        if os.path.exists(image_path):\n",
    "            yield load_image(image_path), compute_position(position)\n",
    "        else:\n",
    "            print(f\"Image manquante : {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MEMORY_SAVING:\n",
    "    \n",
    "    valid_indices = [i for i, path in enumerate(image_list) if path is not None]\n",
    "    valid_image_list = [image_list[i] for i in valid_indices]\n",
    "    valid_label_list = [label_list[i] for i in valid_indices]\n",
    "\n",
    "    generator = lambda: image_generator(valid_image_list, valid_label_list)\n",
    "\n",
    "    dataset = Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(2,), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mélange, division et batch du dataset\n",
    "    dataset = dataset.shuffle(buffer_size=1000, seed=SEED)\n",
    "\n",
    "    dataset_length = len(image_list)\n",
    "    dataset = dataset.apply(tf.data.experimental.assert_cardinality(dataset_length))\n",
    "    dataset = dataset.cache()\n",
    "\n",
    "    validation_size = int(dataset_length * VALIDATION_SPLIT)\n",
    "    test_size = int(dataset_length * TEST_SPLIT)\n",
    "\n",
    "    dataset_validation = dataset.take(validation_size).batch(BATCH_SIZE)\n",
    "    dataset_test = dataset.skip(validation_size).take(test_size).batch(BATCH_SIZE)\n",
    "    dataset_train = dataset.skip(validation_size + test_size).batch(BATCH_SIZE)\n",
    "    \n",
    "    dataset_train = dataset_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_validation = dataset_validation.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_test = dataset_test.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "else:\n",
    "    dataset_length = len(image_list)\n",
    "\n",
    "    images = np.zeros((dataset_length, IMAGE_SIZE[0], IMAGE_SIZE[1], 1), dtype=np.float32)\n",
    "    positions = np.zeros((dataset_length, 2), dtype=np.float32)\n",
    "    \n",
    "    for i in tqdm(range(dataset_length)):\n",
    "        image = load_image(image_list[i])\n",
    "        images[i] = image\n",
    "        positions[i] = compute_position(label_list[i])\n",
    "\n",
    "    dataset_images = Dataset.from_tensor_slices(images)\n",
    "    dataset_positions = Dataset.from_tensor_slices(positions)\n",
    "\n",
    "    dataset = Dataset.zip((dataset_images, dataset_positions)).shuffle(SEED)\n",
    "\n",
    "    dataset_validation = dataset.take(int(dataset_length * VALIDATION_SPLIT))\n",
    "    dataset_test = dataset.skip(len(dataset_validation)).take(int(dataset_length * TEST_SPLIT))\n",
    "    dataset_train = dataset.skip(len(dataset_validation) + len(dataset_test)).take(dataset_length - len(dataset_validation) - len(dataset_test))\n",
    "\n",
    "    dataset_validation = dataset_validation.batch(BATCH_SIZE)\n",
    "    dataset_test = dataset_test.batch(BATCH_SIZE)\n",
    "    dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "    \n",
    "    dataset_train = dataset_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_validation = dataset_validation.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_test = dataset_test.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    images = None\n",
    "    positions = None\n",
    "\n",
    "print(\"Datasets shapes:\")\n",
    "print(dataset_train.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_model(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), output_shape=2, model_name=\"cnn_model\"):\n",
    "    inputs = L.Input(shape=input_shape, name=f'{model_name}_input')\n",
    "    x = L.Conv2D(3, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_3_7')(inputs)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_3_7')(x)\n",
    "    x = L.Conv2D(16, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_16_5')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_16_5')(x)\n",
    "    x = L.Dropout(0.5, name=f'{model_name}_dropout_mid')(x)\n",
    "    x = L.Conv2D(48, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_48_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_48_3')(x)\n",
    "    x = L.Conv2D(24, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_24_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_24_3')(x)\n",
    "    x = L.Conv2D(12, kernel_size=3, activation='relu', padding='same', name=f'{model_name}_conv2D_12_3')(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_12_3')(x)\n",
    "    x = L.Dropout(0.5, name=f'{model_name}_dropout')(x)\n",
    "    x = L.Flatten(name=f'{model_name}_global_avg')(x)\n",
    "    x = L.Dense(16, activation='relu', name=f'{model_name}_dense_128')(x)\n",
    "    outputs = L.Dense(output_shape, activation='softmax', name=f'{model_name}_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "model = create_custom_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_model_v2(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), output_shape=2, model_name=\"cnn_transformer\"):\n",
    "    inputs = L.Input(shape=input_shape, name=f'{model_name}_input')\n",
    "    \n",
    "    x = L.Conv2D(16, kernel_size=3, activation='relu', strides=2, kernel_regularizer=l2(1e-4), name=f'{model_name}_conv2D_16')(inputs)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_16')(x)\n",
    "    \n",
    "    x = L.Conv2D(32, kernel_size=3, activation='relu', dilation_rate=2, name=f'{model_name}_conv2D_32')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_32')(x)\n",
    "    \n",
    "    x = L.Conv2D(128, kernel_size=3, activation='relu', name=f'{model_name}_conv2D_128')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_128')(x)\n",
    "    \n",
    "    x = L.Conv2D(64, kernel_size=3, activation='relu', name=f'{model_name}_conv2D_64')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D(pool_size=2, name=f'{model_name}_maxpool_64')(x)\n",
    "    \n",
    "    attention = L.Flatten()(x)\n",
    "    attention = L.Dense(64, activation='softmax', name=f'{model_name}_attention_dense')(attention)\n",
    "    attention = L.Reshape((1, 1, 64))(attention)\n",
    "    x = L.Multiply()([x, attention])\n",
    "    x = L.Dropout(0.3)(x)\n",
    "\n",
    "    x = L.Flatten(name=f'{model_name}_global_avg_pool')(x)\n",
    "    \n",
    "    x = L.Dense(128, activation='relu', name=f'{model_name}_dense_128')(x)\n",
    "    x = L.Dense(64, activation='relu', kernel_regularizer=l2(1e-4), name=f'{model_name}_dense_64')(x)\n",
    "    outputs = L.Dense(output_shape, activation='softmax', name=f'{model_name}_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"adam\", loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = create_custom_model_v2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Surveille la perte de validation\n",
    "    factor=0.5,          # Réduction du learning rate par un facteur de 0.5\n",
    "    patience=10,          # Nombre d'époques sans amélioration avant réduction\n",
    "    min_lr=1e-10          # Limite minimale du learning rate\n",
    ")\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "history = model.fit(dataset_train, validation_data=dataset_validation, epochs=EPOCHS, callbacks=[reduce_lr])\n",
    "emissions = tracker.stop()\n",
    "\n",
    "plt.plot(history.history['val_mae'], label='train')\n",
    "print(f\"Total emissions: {emissions} kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientNet_model(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), output_shape=2, model_name=\"efficientNet\"):\n",
    "    inputs = L.Input(shape=input_shape, name=f'{model_name}_input')\n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=None)\n",
    "    x = base_model.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dense(128, activation='relu', name=f'{model_name}_dense_128')(x)\n",
    "    x = L.Dense(64, activation='relu', name=f'{model_name}_dense_64')(x)\n",
    "    outputs = L.Dense(output_shape, activation='softmax', name=f'{model_name}_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = create_efficientNet_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Surveille la perte de validation\n",
    "    factor=0.5,          # Réduction du learning rate par un facteur de 0.5\n",
    "    patience=10,          # Nombre d'époques sans amélioration avant réduction\n",
    "    min_lr=1e-10          # Limite minimale du learning rate\n",
    ")\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "history = model.fit(dataset_train, validation_data=dataset_validation, epochs=EPOCHS, callbacks=[reduce_lr])\n",
    "emissions = tracker.stop()\n",
    "\n",
    "plt.plot(history.history['val_mae'], label='train')\n",
    "print(f\"Total emissions: {emissions} kg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
