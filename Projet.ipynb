{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERLI - AI4Industry - 2025\n",
    "\n",
    "---\n",
    "Notebook de Tom BOIREAU\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"dataset/\"\n",
    "IMAGE_SIZE = (1280, 720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables système"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder exists\n",
      "Reading subfolder:  part001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:29<00:00, 66.92it/s] \n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "label_list = []\n",
    "if os.path.exists(DATASET_FOLDER):\n",
    "    print(\"Dataset folder exists\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    for subfolders in os.listdir(DATASET_FOLDER):\n",
    "        print(\"Reading subfolder: \", subfolders)\n",
    "        subfolder_path = os.path.join(DATASET_FOLDER, subfolders)\n",
    "        \n",
    "        for file in tqdm(os.listdir(subfolder_path)):\n",
    "            if file.endswith('.png'):\n",
    "                image_path = os.path.join(subfolder_path, file)\n",
    "                file_name = file.split(\".\")[0]\n",
    "                json_path = os.path.join(subfolder_path, file_name + \".json\")\n",
    "                \n",
    "                if os.path.exists(json_path) and os.path.exists(image_path):\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, IMAGE_SIZE)\n",
    "                    image_list.append(image)\n",
    "                    \n",
    "                    with open(json_path) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                        label_list.append(data)\n",
    "                else:\n",
    "                    print(\"json file does not exist for: \", file)\n",
    "                    \n",
    "        break\n",
    "            \n",
    "else:\n",
    "    raise Exception(\"Dataset folder does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_lst = [ \n",
    "    [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0], \n",
    "    [255, 0, 255], [0, 255, 255], [128, 0, 0], [0, 128, 0], \n",
    "    [0, 0, 128], [128, 128, 0], [128, 0, 128], [0, 128, 128], \n",
    "    [192, 0, 0], [0, 192, 0], [0, 0, 192], [192, 192, 0], \n",
    "    [192, 0, 192], [0, 192, 192], [64, 0, 0], [0, 64, 0], \n",
    "    [0, 0, 64], [64, 64, 0], [64, 0, 64], [0, 64, 64]\n",
    "]\n",
    "# Function to apply watershed segmentation\n",
    "def apply_watershed(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "    \n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations = 3)\n",
    "    \n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.05 * dist_transform.max(), 255, 0)\n",
    "    \n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    markers = cv2.watershed(image, markers)\n",
    "    \n",
    "    new_image = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "    for i in range(2, len(colors_lst) + 1):\n",
    "        new_image[markers == i] = colors_lst[i - 1]\n",
    "        \n",
    "    new_image[markers == -1] = [255, 255, 255]\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "# Display the segmented images as a video stream\n",
    "for img in image_list:\n",
    "    \n",
    "    cv2.imshow('Segmented Image', apply_watershed(img))\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(100) & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"segmented_image.png\", apply_watershed(img))\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
