{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERLI - AI4Industry - 2025\n",
    "\n",
    "---\n",
    "Notebook du Groupe rouge foncé (on aurait préféré le bleu)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"dataset/\"\n",
    "IMAGE_SIZE = (848, 480)\n",
    "MASK_FILE = \"mask1.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables système"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder exists\n",
      "Reading subfolder: dataset/part001\n",
      "Reading subfolder: dataset/part003\n",
      "Reading subfolder: dataset/part004\n",
      "Reading subfolder: dataset/part009\n",
      "Reading subfolder: dataset/part012\n",
      "Reading subfolder: dataset/part000\n",
      "Reading subfolder: dataset/part011\n",
      "Reading subfolder: dataset/part007\n",
      "Reading subfolder: dataset/part002\n",
      "Reading subfolder: dataset/part006\n",
      "Reading subfolder: dataset/part008\n",
      "Reading subfolder: dataset/part013\n",
      "Reading subfolder: dataset/part010\n",
      "Reading subfolder: dataset/part014\n",
      "Reading subfolder: dataset/part005\n",
      "Finished reading subfolder: dataset/part014\n",
      "Finished reading subfolder: dataset/part011\n",
      "Finished reading subfolder: dataset/part003\n",
      "Finished reading subfolder: dataset/part012\n",
      "Finished reading subfolder: dataset/part013\n",
      "Finished reading subfolder: dataset/part007\n",
      "Finished reading subfolder: dataset/part009\n",
      "Finished reading subfolder: dataset/part006\n",
      "Finished reading subfolder: dataset/part002\n",
      "Finished reading subfolder: dataset/part004\n",
      "Finished reading subfolder: dataset/part010\n",
      "Finished reading subfolder: dataset/part005\n",
      "Finished reading subfolder: dataset/part001\n",
      "Finished reading subfolder: dataset/part008\n",
      "Finished reading subfolder: dataset/part000\n"
     ]
    }
   ],
   "source": [
    "data_lock = threading.Lock() \n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "mask = cv2.imread(MASK_FILE)\n",
    "\n",
    "def read_subfolder(subfolder_path, image_size, image_list, label_list):\n",
    "    print(f\"Reading subfolder: {subfolder_path}\")\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        if file.endswith('.png'):\n",
    "            image_path = os.path.join(subfolder_path, file)\n",
    "            file_name = file.split(\".\")[0]\n",
    "            json_path = os.path.join(subfolder_path, file_name + \".json\")\n",
    "\n",
    "            index = int(file_name.split(\"_\")[1])\n",
    "\n",
    "            if os.path.exists(json_path) and os.path.exists(image_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, image_size)\n",
    "                image = cv2.bitwise_and(image, mask)\n",
    "\n",
    "                with data_lock:\n",
    "                    image_list[index] = image\n",
    "                    with open(json_path) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                        label_list[index] = data\n",
    "            else:\n",
    "                print(f\"json file does not exist for: {file}\")\n",
    "    print(f\"Finished reading subfolder: {subfolder_path}\")\n",
    "\n",
    "if os.path.exists(DATASET_FOLDER):\n",
    "    print(\"Dataset folder exists\")\n",
    "    \n",
    "    dataset_len = 1\n",
    "    for subfolders in os.listdir(DATASET_FOLDER):\n",
    "        subfolder_path = os.path.join(DATASET_FOLDER, subfolders)\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith('.png'):\n",
    "                dataset_len += 1\n",
    "                \n",
    "    image_list = np.zeros((dataset_len, IMAGE_SIZE[1], IMAGE_SIZE[0], 3), dtype=np.uint8)\n",
    "    label_list = np.zeros((dataset_len, 1), dtype=object)\n",
    "    \n",
    "    threads = []\n",
    "\n",
    "    # Lancer un thread pour chaque sous-dossier\n",
    "    for subfolder in os.listdir(DATASET_FOLDER):\n",
    "        subfolder_path = os.path.join(DATASET_FOLDER, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            thread = threading.Thread(target=read_subfolder, args=(subfolder_path, IMAGE_SIZE, image_list, label_list))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "    # Attendre que tous les threads soient terminés\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "else:\n",
    "    raise Exception(\"Dataset folder does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_lst = [ \n",
    "    [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0], \n",
    "    [255, 0, 255], [0, 255, 255], [128, 0, 0], [0, 128, 0], \n",
    "    [0, 0, 128], [128, 128, 0], [128, 0, 128], [0, 128, 128], \n",
    "    [192, 0, 0], [0, 192, 0], [0, 0, 192], [192, 192, 0], \n",
    "    [192, 0, 192], [0, 192, 192], [64, 0, 0], [0, 64, 0], \n",
    "    [0, 0, 64], [64, 64, 0], [64, 0, 64], [0, 64, 64]\n",
    "]\n",
    "# Function to apply watershed segmentation\n",
    "def apply_watershed(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "    \n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations = 3)\n",
    "    \n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.3 * dist_transform.max(), 255, 0)\n",
    "    \n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    markers = cv2.watershed(image, markers)\n",
    "    \n",
    "    new_image = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "    for i in range(2, len(colors_lst) + 1):\n",
    "        new_image[markers == i] = np.array(colors_lst[i - 1]) * 0.2 + image[markers == i] * 0.8\n",
    "        \n",
    "    new_image[markers == -1] = image[markers == -1]\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(image, k = 5) :\n",
    "    Z = image.reshape((-1,3))\n",
    "    Z = np.float32(Z)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = k\n",
    "    ret,label,center=cv2.kmeans(Z, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((image.shape))\n",
    "    \n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the segmented images as a video stream\n",
    "for img in image_list:\n",
    "    \n",
    "    cv2.imshow('Segmented Image', apply_kmeans(img))\n",
    "    if cv2.waitKey(18) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(18) & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"segmented_image.png\", apply_kmeans(img))\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
